Reference Book: Machine Learning by Tom Mitchell
---------------
Chapters(slides/pdfs):
1(ch1.pdf)
2(Ch02.ppt, ch2.pdf)
3(ch3.pdf)
5(ch5.pdf, ML05.ppt, t-test.ppt)
7(ch7.pdf)
8(ch8.pdf, RBF-Network.ppt)
10(SetsOfRules.ppt)
13(Q-Learn-Convergence.ppt, RL-1.ppt)




Links, PPTs and PDFs:
---------------------
N.B. These are the materials which don't really go
     with the topic of the book directly, rather fits
     a bit tangentially

DISCLAIMER: The specifications regarding what parts should be read from the following topics
            were provided by Maruf Zaber. Neither me nor Zaber will be held accountable for
            any discrepancy between the set question and the portions delineated here. Finding
            out exactly what parts were taught from lectures is a rigorous task which Zaber
            did with great excellence. That being said, the reader is requested to keep in mind
            that Sir was quite vague regarding what parts should be read exactly, he sort of
            touched a few things and said to go through the papers - to what extent is unclear.

* Wilcoxon Signed-Rank Test -
	https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test
		-Introduction
		-Assumptions
		-Test Procedure
		-Effect Size

* ROCintro.pdf -
	An Introduction to ROC Analysis - Tom Fawcett
		-Introduction
		-Classifier performance
		-ROC space

* ImbalancedClassDistribution.pdf - 
	Boosting for Learning Multiple Classes with Imbalanced Class Distribution by Sun, Kamel and Wang
		-Abstract
		-Introduction
		-7.1 Leaning Objectives and Evaluation Measures

* Semi-supervised Learning
	- Semi-Supervised_Learning.ppt
	- ch3 SemiSupL.pdf

* liu_acnn98.pdf -
	Simultaneous Learning of Negatively Correlated Neural Networks by Yong Liu and Xin Yao

* published_tsmcB_dec99.pdf -
	Simultaneous Learning of Negatively Correlated Neural Networks in an Ensemble by Yong Liu and Xin Yao

* Online Learning (no materials were provided, but following topics were discussed in class):
	- multi label
	- concept drift
	- concept evolution
	- recurrent class

* Genetic Programming
	- GP.ppt
		-slides 1 to 22

* Imbalanced Data and (Inductive) Learning from Imbalanced Data Sets
	- Class-Imbalances.ppt
		-slides 1 to 18
	- MWMOTE-May82013.ppt
		-slides 1 to 36
	- lecture10-imbalanced.pptx
		-slides 1 to 9
	



Questions of Class Test
-----------------------
N.B. CT2 missing

CT1
---
1. Draw a flowchart showing different components of a learning machine		(05)
2. What are the problems associated with Find-S algorithm?
   Give some ideas how you could avoid these problems.				(05)
3. Which characteristics of a problem are necessary for decision tree learning?
   Explain them briefly.							(05)

CT3
---
1. You are given a set of two dimensional inputs and their corresponding output pair:
   {X_(i,1), X_(i,2), y_i}. We like to use the following locally weighted regression
   model to predict y:
   	y_i = w_0 + ((w_1)^2)(x_(1,i)) + ((w_2)^2)(x_(2,i))			(10)
   Derive the optimal value of w_1 for minimizing the mean-squared-error
   (w_0 and w_2 may appear in your resulting equation). Note that there may be more
   than one possible value of w_1
2. What is the main shortcoming of the k-nearest neighbor algorithm?
   Give some intuitive ideas for avoiding it.					(05)

CT4
---
1. Write the pseudocode for sequential covering algorithm.
   Discuss the advantages and problems of this algorithm.			(10)
2. Explain why learning first-order rules are more powerful
   than propositional rules.							(05)
